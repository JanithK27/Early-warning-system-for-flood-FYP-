{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'F:/FYP project/FYP(Flood)/Real Data/new full data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check for null values\n",
    "print(\"Missing values in each column before processing:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Method 1: Forward Fill (propagate last valid observation forward to fill nulls)\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Method 2: Interpolation (optional, if you want to interpolate instead of forward fill)\n",
    "# df.interpolate(method='linear', inplace=True)\n",
    "\n",
    "# Recheck for null values after filling\n",
    "print(\"Missing values in each column after processing:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Extract input features and target (Water Level for next 1st, 2nd, 3rd hours)\n",
    "X = df[['Discharge Rate (cumecs)', 'Rainfall Data (mm)', 'Water Level (m)']].values\n",
    "y = np.array([df['Water Level (m)'].shift(-i) for i in range(1, 4)]).T[:-3]\n",
    "\n",
    "# Remove the last three rows since they don't have the target data\n",
    "X = X[:-3]\n",
    "\n",
    "# Prepare data using 3 rows (time steps) as input to predict next 3 hours\n",
    "def create_sequences(X, y, time_steps=3):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:(i + time_steps), :])\n",
    "        ys.append(y[i + time_steps - 1])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "time_steps = 3\n",
    "X_seq, y_seq = create_sequences(X, y, time_steps)\n",
    "\n",
    "# Flatten the sequences for Random Forest (since Random Forest doesn't handle sequences like LSTM)\n",
    "X_seq_flat = X_seq.reshape(X_seq.shape[0], -1)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_seq_flat, y_seq, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Standardize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the RandomForestRegressor for each hour (1st, 2nd, and 3rd hour predictions)\n",
    "rf_1st_hour = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_2nd_hour = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_3rd_hour = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_1st_hour.fit(X_train_scaled, y_train[:, 0])\n",
    "rf_2nd_hour.fit(X_train_scaled, y_train[:, 1])\n",
    "rf_3rd_hour.fit(X_train_scaled, y_train[:, 2])\n",
    "\n",
    "# Make predictions\n",
    "y_pred_1st_hour = rf_1st_hour.predict(X_test_scaled)\n",
    "y_pred_2nd_hour = rf_2nd_hour.predict(X_test_scaled)\n",
    "y_pred_3rd_hour = rf_3rd_hour.predict(X_test_scaled)\n",
    "\n",
    "# Combine predictions into a single array\n",
    "y_pred = np.column_stack([y_pred_1st_hour, y_pred_2nd_hour, y_pred_3rd_hour])\n",
    "\n",
    "# Round the predictions to 2 decimal places\n",
    "y_pred = np.round(y_pred, 2)\n",
    "y_test = np.round(y_test, 2)\n",
    "\n",
    "# Calculate accuracy for each hour's prediction\n",
    "def calculate_accuracy(y_true, y_pred, threshold=0.1):\n",
    "    \"\"\"Calculate accuracy by checking if predicted values are within a threshold of actual values.\"\"\"\n",
    "    return np.mean(np.abs(y_true - y_pred) <= threshold)\n",
    "\n",
    "accuracy_1st_hour = calculate_accuracy(y_test[:, 0], y_pred[:, 0])\n",
    "accuracy_2nd_hour = calculate_accuracy(y_test[:, 1], y_pred[:, 1])\n",
    "accuracy_3rd_hour = calculate_accuracy(y_test[:, 2], y_pred[:, 2])\n",
    "\n",
    "print(f\"Accuracy for 1st hour prediction: {accuracy_1st_hour * 100:.2f}%\")\n",
    "print(f\"Accuracy for 2nd hour prediction: {accuracy_2nd_hour * 100:.2f}%\")\n",
    "print(f\"Accuracy for 3rd hour prediction: {accuracy_3rd_hour * 100:.2f}%\")\n",
    "\n",
    "# Create confusion matrices for each hour's prediction\n",
    "def create_confusion_matrix(y_true, y_pred, threshold=0.1):\n",
    "    \"\"\"Create confusion matrix based on whether predictions are within the threshold.\"\"\"\n",
    "    y_true_binary = (y_true > np.mean(y_true)).astype(int)\n",
    "    y_pred_binary = (y_pred > np.mean(y_pred)).astype(int)\n",
    "    return confusion_matrix(y_true_binary, y_pred_binary)\n",
    "\n",
    "conf_matrix_1st_hour = create_confusion_matrix(y_test[:, 0], y_pred[:, 0])\n",
    "conf_matrix_2nd_hour = create_confusion_matrix(y_test[:, 1], y_pred[:, 1])\n",
    "conf_matrix_3rd_hour = create_confusion_matrix(y_test[:, 2], y_pred[:, 2])\n",
    "\n",
    "# Comparing actual vs predicted for first 10 values\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual (Next 1st hour)': y_test[:, 0],\n",
    "    'Predicted (Next 1st hour)': y_pred[:, 0],\n",
    "    'Actual (Next 2nd hour)': y_test[:, 1],\n",
    "    'Predicted (Next 2nd hour)': y_pred[:, 1],\n",
    "    'Actual (Next 3rd hour)': y_test[:, 2],\n",
    "    'Predicted (Next 3rd hour)': y_pred[:, 2]\n",
    "})\n",
    "\n",
    "print(comparison_df.head(10))\n",
    "\n",
    "# Plot actual vs predicted for each of the next 3 hours\n",
    "for i in range(3):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_test[:, i], label=f'Actual Water Level (Next {i+1} hour)')\n",
    "    plt.plot(y_pred[:, i], label=f'Predicted Water Level (Next {i+1} hour)')\n",
    "    plt.title(f'Actual vs Predicted Water Level (Next {i+1} Hour)')\n",
    "    plt.xlabel('Test Samples')\n",
    "    plt.ylabel('Water Level (m)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Calculate and display MAE for each hour prediction\n",
    "mae_1st_hour = mean_absolute_error(y_test[:, 0], y_pred[:, 0])\n",
    "mae_2nd_hour = mean_absolute_error(y_test[:, 1], y_pred[:, 1])\n",
    "mae_3rd_hour = mean_absolute_error(y_test[:, 2], y_pred[:, 2])\n",
    "\n",
    "print(f'Mean Absolute Error for 1st hour prediction: {mae_1st_hour:.2f}')\n",
    "print(f'Mean Absolute Error for 2nd hour prediction: {mae_2nd_hour:.2f}')\n",
    "print(f'Mean Absolute Error for 3rd hour prediction: {mae_3rd_hour:.2f}')\n",
    "\n",
    "# Create confusion matrices by binning the actual and predicted values into ranges\n",
    "def create_binned_confusion_matrix(y_true, y_pred, hour):\n",
    "    bins = np.linspace(min(y_true.min(), y_pred.min()), max(y_true.max(), y_pred.max()), 10)  # Create 10 bins\n",
    "    y_true_binned = np.digitize(y_true, bins)\n",
    "    y_pred_binned = np.digitize(y_pred, bins)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_true_binned, y_pred_binned)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Confusion Matrix for Next {hour} Hour Prediction')\n",
    "    plt.xlabel('Predicted Bins')\n",
    "    plt.ylabel('Actual Bins')\n",
    "    plt.show()\n",
    "\n",
    "# Generate confusion matrices for next 1st, 2nd, and 3rd hour predictions\n",
    "create_binned_confusion_matrix(y_test[:, 0], y_pred[:, 0], '1st')\n",
    "create_binned_confusion_matrix(y_test[:, 1], y_pred[:, 1], '2nd')\n",
    "create_binned_confusion_matrix(y_test[:, 2], y_pred[:, 2], '3rd')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
